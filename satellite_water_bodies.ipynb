{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition of water in satellite pictures using Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we train a Unet to recognise water in satellite pictures. The unet will be built within Tensorflow with ROCm support (that will fall back to CPU if no GPU is found). The available data consists of 2841 images and corresponding masks identifying water, such as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"models/unet/data/water/Images/water_body_3.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "<td> <img src=\"models/unet/data/water/Masks/water_body_3.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the neural network\n",
    "\n",
    "First, let's import all the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "from keras import Model\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to prepare the data. First we prescribe the size of the images (and thus of the input layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 128\n",
    "\n",
    "image_path = 'models/unet/data/water/Images/'\n",
    "mask_path = 'models/unet/data/water/Masks/'\n",
    "\n",
    "\n",
    "# Lists of images and masks names\n",
    "image_names = sorted(next(os.walk(image_path))[-1])\n",
    "mask_names = sorted(next(os.walk(mask_path))[-1])\n",
    "\n",
    "images = np.zeros(shape=(len(image_names),SIZE, SIZE, 3))\n",
    "masks = np.zeros(shape=(len(image_names),SIZE, SIZE, 1))\n",
    "\n",
    "for id in tqdm(range(len(image_names)), desc=\"Images\"):\n",
    "  path = image_path + image_names[id]\n",
    "  img = np.asarray(Image.open(path)).astype('float')/255.\n",
    "  img = cv.resize(img, (SIZE,SIZE), cv.INTER_AREA)\n",
    "  images[id] = img\n",
    "\n",
    "for id in tqdm(range(len(mask_names)), desc=\"Mask\"):\n",
    "  path = mask_path + mask_names[id]\n",
    "  mask = np.asarray(Image.open(path)).astype('float')/255.\n",
    "  mask = cv.resize(mask, (SIZE,SIZE), cv.INTER_AREA)\n",
    "  masks[id] = mask[:,:,:1]\n",
    "\n",
    "# Train test split\n",
    "images_train, images_test, mask_train, mask_test = train_test_split(images, masks, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can know prescribe the layout of the Unet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_layer, start_neurons):\n",
    "    # Contraction path\n",
    "    conv1 = Conv2D(start_neurons, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(start_neurons*2, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons*2, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(start_neurons*4, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(start_neurons*4, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(start_neurons*8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(start_neurons*8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons*16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = Conv2D(start_neurons*16, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "    \n",
    "    # Expansive path\n",
    "    deconv4 = Conv2DTranspose(start_neurons*8, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons*8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons*8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(start_neurons*4, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons*4, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons*4, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(start_neurons*2, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons*2, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons*2, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(start_neurons*1, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    \n",
    "    # Last conv and output\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "# Compile unet model\n",
    "input_layer = Input((SIZE, SIZE, 3))\n",
    "output_layer = unet_model(input_layer = input_layer, start_neurons = 16)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_threshold(image, threshold=0.25):\n",
    "  return image>threshold\n",
    "\n",
    "epochs = 2 \n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(images_train, mask_train,\n",
    "                    validation_data=[images_test, mask_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
